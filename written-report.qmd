---
title: "The relationship between race, gender, first-gen status, and college type for sleep and GPA in college students"
author: "Wale: Liane, Amy, Eshan, Will"
date: "10/31/24"
format: pdf
execute: 
  warning: false
  message: false
  echo: false
editor: visual
---

```{r}
#| label: load packages and data
library(patchwork)
library(tidyverse)
library(GGally)
library(dplyr)
library(knitr)
library(broom)
library(pROC)
library(car)
library(yardstick)
library(rms)

university_dataset <- read_csv("data/cmu-sleep.csv")
#glimpse(university_dataset)
```

Your written report goes here!

::: callout-important
Before you submit, make sure your code chunks are turned off with `echo: false` and there are no warnings or messages with `warning: false` and `message: false` in the YAML.
:::

Introduction

As college students, we are interested in exploring how academic performance is affected differently by lack of sleep, whether a student goes to a public or private university, and more as many of these issues affect us currently. As shown in previous research, sleep impacts students’ academic achievement significantly [@effect_sleep], but we aim to explore this in terms of the time students went to bed, average sleep time, and more while also accounting for students’ background and the type of university they go to. It is generally understood that lower levels of sleep negatively impact academic performance, but we are interested in how this impact varies or might be challenged by different factors and how we may be able to predict academic performance based on different factors. We hypothesize that the average time in bed will have the largest effect on cumulative GPA and that having less variation in bed time will lead to a higher cumulative GPA. We also anticipate the type of university students attend and first-gen status to have an affect on students' GPA. Our research question is as follows: How does sleep impact academic performance across demographics of college students?

Exploratory Data Analysis

Description of the data set and key variables.

The data was originally collected in 2019, with the participants being first-year students at the following three universities: Carnegie Mellon University (CMU), a STEM-focused private university, The University of Washington (UW), a large public university, and Notre Dame University (ND), a private Catholic university. To collect data on sleep, each participating student was given a Fitbit device to track their sleep and physical activity for a month in the spring term, and grade and demographic data was provided by university registrars.

There are originally 634 observations, representing the 634 participants in this study. We filtered out students whose data was collected less than 50% of the term, leaving us with 588 participants. Race is a binary variable separated into underrepresented students and non-underrepresented students with 0 being underrepresented and 1 being non-underrepresented. Students are considered underrepresented if either parent is Black, Hispanic or Latino, Native American, or Pacific, and students are deemed non-underrepresented if both parents have White or Asian ancestry. The gender of the subject is also binary with 0 being male and 1 being female. First-generation status is binary with 0 being non-first gen and 1 being first-gen. The mean successive squared difference of bedtime measures the bedtime variability, specifically the average of the squared difference of bedtime on consecutive nights. To measure academic performance, we will be using variables `term_gpa` and `cum_gpa` (cumulative GPA) as response variables. Furthermore, we created the variable `gpa_split` which uses a threshold of a 3.0 GPA to determine whether a student has a "low" or "high" GPA.

```{r}
university_clean <- university_dataset |>
  mutate(university = case_when(
    study %in% c(1, 5) ~ "stem_priv",
    study %in% c(2, 3) ~ "public",
    study == 4 ~ "cath_priv"
  )) |>
  filter(frac_nights_with_data > .50) |>
  filter(demo_firstgen != 2)
#glimpse(university_clean)

# need to continue cleaning for NAs, removing unused variables (ZtoZterm)? also maybe factor(demo firstgen, race, etc)
```

Here, we created a new variable `university`, which combines studies done at the same universities on different years ranging from 2016 to 2019.

Univariate EDA of The Response & Key Predictor Variables:

```{r}
#| label: univariate-EDA


# university_clean |> 
#   select(term_gpa, cum_gpa, TotalSleepTime, bedtime_mssd, demo_firstgen, university, daytime_sleep) |>
#   ggpairs()

p1 <- university_clean |>
  ggplot(aes(x = term_gpa)) +
  geom_histogram() +
  labs(title = "Distribution of the Term GPA",
       x = "Term GPA",
       y = "Count")

p2 <- university_clean |>
  ggplot(aes(x = term_gpa)) +
  geom_histogram(bins = 12) +
  labs(title = "Distribution of the Term GPA",
       subtitle = "by University",
       x = "Term GPA",
       y = "Count") +
  facet_wrap(~university)

p3 <- university_clean |>
  ggplot(aes(x = cum_gpa)) +
  geom_histogram() +
  labs(title = "Distribution of the Cumulative GPA",
       x = "Cumulative GPA",
       y = "Count")

p4 <- university_clean |>
  ggplot(aes(x = cum_gpa)) +
  geom_histogram(bins = 12) +
  labs(title = "Distribution of the Cumulative GPA",
       subtitle = "by University",
       x = "Cumulative GPA",
       y = "Count") +
  facet_wrap(~university)

termgpa_ss <- university_clean |>
  group_by(university) |>
  summarize(
    mean_tgpa = mean(term_gpa, na.rm = TRUE),
    median_tgpa = median(term_gpa, na.rm = TRUE),
    sd_tgpa = sd(term_gpa, na.rm = TRUE),
    min_tgpa = min(term_gpa, na.rm = TRUE),
   max_tgpa = max(term_gpa, na.rm = TRUE),
   count = n()
  ) |>
  kable(digits = 3)
termgpa_ss

gpa_ss <- university_clean |>
  group_by(university) |>
   summarize(
     mean_cgpa = mean(cum_gpa, na.rm = TRUE),
     median_cgpa = median(cum_gpa, na.rm = TRUE),
     sd_cgpa = sd(cum_gpa, na.rm = TRUE),
     min_cgpa = min(cum_gpa, na.rm = TRUE),
     max_cgpa = max(cum_gpa, na.rm = TRUE),
     count = n()
   ) |>
   kable(digits = 3)
 gpa_ss

p5 <- university_clean |>
  ggplot(aes(x = TotalSleepTime)) + 
  geom_histogram() +
  labs(title = "Distribution of the Total Sleep Time",
       x = "Total Sleep Time in Minutes", #consider switching to hours
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)


p6 <- university_clean |>
  ggplot(aes(x = bedtime_mssd)) + 
  geom_histogram() +
  labs(title = "Distribution of the Bedtime Variability",
       x = "Mean successive squared difference of bedtime",
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)


p7 <- university_clean |>
  ggplot(aes(x = frac_nights_with_data)) + 
  geom_histogram() +
  labs(title = "Distribution of the Fraction of Nights With Data",
       x = "Fraction of Nights With Data",
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)


p8 <- university_clean |>
  ggplot(aes(x = daytime_sleep)) + 
  geom_histogram() +
  labs(title = "Distribution of Daytime Sleep",
       x = "Daytime Sleep in Minutes",
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)

  
p9 <- university_clean |>
  group_by(demo_race) |>
  summarise(count = n(), na.rm = TRUE) |>
  mutate(race_percentage = count / sum(count) * 100) |>
  ggplot(aes(x = "", y = race_percentage, fill = factor(demo_race, labels =
                            c("Underrepresented", "Non-Underrepresented")))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Distribution of \nUnderrepresented Vs. \nNon-Underrepresented\n
       Students",
       fill = "Race") + 
  theme(
  plot.title = element_text(size = 10)
)


p10 <- university_clean |>
  group_by(demo_gender) |>
  summarise(count = n(), na.rm = TRUE) |>
  mutate(gender_percentage = count / sum(count) * 100) |>
  ggplot(aes(x = "", y = gender_percentage, fill = factor(demo_gender, labels =
                            c("Male", "Female")))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Distribution of \nGender",
       fill = "Gender")  + 
  theme(
  plot.title = element_text(size = 10)
)


p11 <- university_clean |>
  group_by(demo_firstgen) |> 
  summarise(count = n(), na.rm = TRUE) |>
  mutate(firstgen_percentage = count / sum(count) * 100) |>
  ggplot(aes(x = "", y = firstgen_percentage, fill = factor(demo_firstgen,
                                                            labels =
                            c("Non-First Gen", "First Gen")))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar("y", start = 0) +
  labs(title = "Distribution of \nFirst-generation Status",
       fill = "First-generation Status") +
  theme(
  plot.title = element_text(size = 10)
)


na_table <- university_clean |>
  group_by(university) |>
  summarize(
    total_count = n(),
    na_count = sum(is.na(term_units)),
    non_na_count = sum(!is.na(term_units))
  ) |>
  kable(digits = 3)
na_table

gpa_plots <- (p1 | p2) / (p3 | p4) 
gpa_plots 

sleep_plots <- (p5 | p6) / (p7 | p8)
sleep_plots

demographics_plots <- (p9 | p10 | p11) +
  plot_layout(guides = "collect") +
  plot_annotation(
    title = "Demographics Distributions",
    theme = theme(
      plot.title = element_text(size = 18, face = "bold", hjust = 0.5, margin = margin(b = 15))
    )
  )
demographics_plots

#a lot of NA values for the Catholic school -> will not use this variable
#for analyses


```

Bivariate EDA of The Response & Key Predictor Variables:

```{r}

university_clean |>
  ggplot(aes(
    x = TotalSleepTime/60,
    y = cum_gpa,
    color = factor(demo_race, labels = c("Underrepresented", "Non-Underrepresented"))
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Cumulative GPA vs. Total Sleep Time by Race",
    x = "Total Sleep Time (hours)",
    y = "Cumulative GPA /4.0",
    color = "Underrepresented Status"
  )


university_clean |>
  filter(!is.na(demo_gender)) |>
  ggplot(aes(
    x = TotalSleepTime,
    y = cum_gpa,
    color = factor(demo_race, labels = c("Male", "Female"))
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Cumulative GPA vs. Total Sleep Time by Gender",
    x = "Total Sleep Time (hours)",
    y = "Cumulative GPA /4.0",
    color = "Gender"
  )

university_clean |>
  filter(!is.na(demo_firstgen)) |>
  ggplot(aes(
    x = TotalSleepTime,
    y = term_gpa,
    color = factor(demo_firstgen, labels = c("Not First-Generation", "First-Generation"))
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Term GPA vs. Total Sleep Time by First-Generation Status",
    x = "Total Sleep Time (hours)",
    y = "Term GPA /4.0",
    color = "First-Generation Status"
  )



university_clean |>
  mutate(threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"))|>
  ggplot(aes(x = TotalSleepTime/60, y = term_gpa, color = factor(threshold_gpa))) +
  facet_wrap(~ university,
             labeller = labeller(
              university = c("cath_priv" = "Private (Catholic)",
                             "public" = "Public",
                             "stem_priv" = "Private (STEM)"))) + 
  geom_point(alpha = 0.3) +
  geom_smooth(aes(color = factor(threshold_gpa)), method = "lm", se = FALSE) +
  scale_color_manual(values = c("low" = "blue", "high" = "red")) +
  labs(
    title = "Relationship between Total Sleep Time and GPA by University Type",
    x = "Total Sleep Time (hours)",
    y = "Term GPA /4.0",
    color = "GPA Threshold"
    
  )



university_clean |>
  ggplot(aes(
    x = university,
    y = cum_gpa,
    fill = university
  )) +
  geom_boxplot() +
  labs(
    title = "Distribution of Cumulative GPA by University",
    x = "University",
    y = "Cumulative GPA"
  )



university_clean |>
  ggplot(aes(
    x = as.factor(demo_firstgen),
    y = cum_gpa
  )) +
  geom_boxplot() 


university_clean |>
  ggplot(aes(
    x = bedtime_mssd, 
    y = cum_gpa, 
    color = university
  )) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE)



university_clean |>
  ggplot(aes(
    x = daytime_sleep,
    y = term_gpa
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Term GPA vs. Daytime Sleep",
    x = "Daytime Sleep (minutes)",
    y = "Term GPA /4.0"
  )

university_clean |>
  mutate(threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"))|>
  ggplot(aes(
    x = Zterm_units_ZofZ,
    y = TotalSleepTime,
    color = university
  )) + 
  facet_wrap(~threshold_gpa) +
  geom_point() +
  geom_smooth(method = "lm")

university_clean |>
  mutate(threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"))|>
  mutate(daytime_sleep_lvl = if_else(daytime_sleep > 60, "high", "low")) |>
  ggplot(aes(
    x = daytime_sleep,
    y = term_gpa,
    color = daytime_sleep_lvl 
  )) +
  facet_wrap(~threshold_gpa) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Term GPA by Daytime Sleep",
    x = "Daytime Sleep (minutes)",
    y = "Term GPA /4.0",
    color = "Daytime Sleep Length"
  )

```

From the graphs above, a few of the key variables seem to have some interaction effects, and a few others do not. The first graph is a scatterplot of the relationship between total sleep time and cumulative GPA, factored by race, where red points were underrepresented students, and blue points were non-underrepresented students. The slopes of the lines best fit for each level are very similar but the slope for the underrepresented students is slightly larger than the slopes for non-underrepresented students, so there might be an interaction effect there that is worth further analysis.

The second graph, is also a scatterplot of the relationship between total sleep time and cumulative GPA, but instead factored by gender, where the red points represent male gender and the blue points represent female gender. The slopes for the line best fit for each level were essentially the same, so there is no obvious interaction effect in this graph that is worth further analysis.

The third graph shows the relationship between a student's term GPA and their total sleep time, but is facet wrapped by the university the student attended. A fourth variable, `threshold_gpa`, is a factor of 0 and 1, where 0 represents that the student's term GPA is greater than or equal to their cumulative GPA, and 1 represents that the student's term GPA is less than their cumulative GPA. This essentially tells us whether the student's term GPA is better or worse than their average GPA. Since this study only collected data during the singular term, this variable will help us determine whether a student with a low term GPA relative to their cumulative GPA is predictive of that student's total sleep time. There are a few interesting things to note of this graph. First, the term GPA of students at the STEM university seem to be more variable than the other two universities, and the total sleep time of the students at the STEM university seem to be on average lower than the other two universities.

In regards to the interaction effects, it seems as if for all three universities there is an interaction effect between students whose term GPA is less than their cumulative and student's whose term GPA is greater than or equal to their cumulative GPA. We assume this, because for all three universities, we fit a line best fit to for both term GPA \< cumulative GPA and vise versa, and the slopes of both lines for all three universities are different. Most notably, for the private catholic university and the public university, the slopes of the level for term GPA \< cumulative GPA is greater than the slopes of the level for term GPA $\ge$ cumulative GPA. This means that there is a potential interaction effect that could be explored further.

Another graph with another potential interaction effect is the sixth graph, which plots the relationship between the mean successive squared difference of bedtimes (bedtime_mssd) and a student's cumulative GPA. The points on this scatterplot were differentiated by university, with red representing the catholic private university, green representing the public university, and blue representing the STEM private university. We fit the line best fit for each of these levels, and the slope of the line for the catholic private university and the stem private university were essentially the same, but the slope of the line for the public university was slightly smaller, which means there could be a potential interaction effect there that is worth further exploration.

We created the variable `daytime_sleep_lvl`, which uses a threshold of 60 minutes to determine whether a student's average daytime sleep is long (high) or short (low).

update

Methodology

```{r}
university_clean <- university_clean |>
  mutate(gpa_split = if_else(
    cum_gpa >= 3.0, "High GPA", "Low GPA"),
  threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"),
  daytime_sleep_lvl = if_else(daytime_sleep > 60, "high", "low"))
  
log_model <- glm(as.factor(gpa_split) ~ TotalSleepTime + university + daytime_sleep_lvl + demo_firstgen + demo_gender + bedtime_mssd + demo_race + threshold_gpa, data = university_clean, family = binomial)

tidy(log_model) |>
  kable(digits = 3)


tidy(vif(log_model))
```

```{r}
ggplot(university_clean, aes(x = university, fill = gpa_split)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Distribution of High and Low Cumulative GPA by University Type",
    x = "University Type",
    y = "Count",
    fill = "GPA Split"
  ) +
  theme_minimal()
```

We decided that the best way to approach this is by transforming GPA into a binary variable where "High" is considered a GPA of over 3, and "Low" is below. Using this transformed response variable, we figured the best way to approach this would be to use a logistic regression model, given the binary nature of the response. We fit this model with essentially every single one of our predictors (seen above). We saw that (by p-value), some of these predictors were not significant, and so we needed to do some more digging to figure out what was necessary to use in the model.

```{r}

sig_fit <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa, data = university_clean, family = binomial) #change base to another school
tidy(sig_fit) |>
  kable(digits = 3)

university_fit1 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime, data = university_clean, family = binomial)

tidy(university_fit1) |>
  kable(digits = 3)

anova(sig_fit, university_fit1, test = "Chisq")
# TotalSleepTime we should include.

```

We then created a new model, sig_fit, that isolated only the variables that were seen as significant in the output from our original model. However, there were certain variables that we felt were still necessary to assess further, and so we used a Drop-in Deviance test to compare two models, the exact same, except one included TotalSleepTime, and the other didn't. Given TotalSleepTime being central to our entire research motivation, we wanted to investigate further, and our anova table showed us the p-value being 0.004, meaning its inclusion significantly improves the fit of the model.

I think this whole section can be deleted (below).

```{r}

data_ur1 <- tibble(demo_race = 0, university = "stem_priv", threshold_gpa = "high") #area under curve, BIC for prediction, hypothesis testing
predict.glm(sig_fit, data_ur1, type = "response") #interaction term - drop in deviance

data_ur2 <- tibble(demo_race = 0, university = "cath_priv", threshold_gpa = "high")
predict.glm(sig_fit, data_ur2, type = "response")
#why is it so low lol

data_ur3 <- tibble(demo_race = 0, university = "public", threshold_gpa = "high")
predict.glm(sig_fit, data_ur3, type = "response")

```

predict prob of 21.7% that

-   underrepresented

-   stem

-   that's doing better spring sem than fall sem

has a GPA of at least 3.0.

```{r}


```

multicolinearity check for TotalSleepTime and daytime_sleep

Up until here Can be deleted.

$$
H_0: \beta_{\text{TotalSleepTime}} = 0\\
H_a: \beta_{\text{TotalSleepTime}} \neq 0
$$

```{r}

another_model <- glm(as.factor(gpa_split) ~ TotalSleepTime, data = university_clean, family = binomial)

tidy(another_model) |>
  kable(digits = 3)


university_fit1 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime, data = university_clean, family = binomial)

tidy(university_fit1) |>
  kable(digits = 3)



```

```{r}


university_fit2 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + demo_firstgen + TotalSleepTime, data = university_clean, family = binomial)

anova(university_fit1, university_fit2, test = "Chisq")

university_fit3 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + bedtime_mssd + TotalSleepTime, data = university_clean, family = binomial)

anova(university_fit1, university_fit3, test = "Chisq")

university_fit4 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + daytime_sleep_lvl + TotalSleepTime, data = university_clean, family = binomial)

anova(university_fit1, university_fit4, test = "Chisq")


```

We then repeated this same drop-in deviance process with the "first-gen" demographic variable, the bedtime variable, and the daytime_sleep variable. The p-values generated by the first two ANOVA tables indicate that they do not significantly improve model-fit, however the inclusion of daytime_sleep_lvl does.

```{r}

tidy(vif(university_fit1))

tidy(vif(university_fit4))

```

We then decided to check for multicollinearity given the interconnected nature of some of the variables.

```{r}
university_final <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + daytime_sleep_lvl, data = university_clean, family = binomial)


vif(university_final)


```

We renamed the "model_4" from above to be the final model. The VIFs for the levels of university are somewhat high, however they are not above 10, and so are not at a concerning level. In the final draft we can do further investigation into why we are seeing these issues.

## Results

The final model we determined is:

**\*\*ADD EQUATION**

```{r}
tidy(university_final)
```

To confirm that the final model with predictors `university`, `demo_race`, `threshold_gpa`, `TotalSleepTime`, and `daytime_sleep_lvl` is better for predicting a high or low GPA (`gpa_split`) than the reduced model with initial significant predictors `university`, `demo_race`, and `threshold_gpa`, ROC and AUC were calculated for both models and compared.

The final model we chose showed a larger AUC. The area under the curve for the final model is 0.778, whereas for the reduced model it is 0.75, showing that this final model maximizes sensitivity, the True Positive Rate, and minimizes 1 - specificity, the False Positive Rate, slightly better than the reduced model.

```{r}

final_roc <- augment(university_final) |>
  roc_curve('as.factor(gpa_split)', .fitted, event_level = "second")

red_roc <- augment(sig_fit) |>
  roc_curve('as.factor(gpa_split)', .fitted, event_level = "second")

combined_plot <- autoplot(red_roc, color = "blue") +
  ggtitle("ROC Curves: Final Model vs. Reduced Model") +
  xlab("1 - Specificity") +
  ylab("Sensitivity") +
  geom_line(data = final_roc, aes(x = 1 - specificity, y = sensitivity, color = "Final Model")) + 
  geom_line(data = red_roc, aes(x = 1 - specificity, y = sensitivity, color = "Reduced Model")) +
  scale_color_manual(values = c("Final Model" = "red", "Reduced Model" = "black")) +
  labs(color = "Model")

combined_plot

fin_aug <- augment(university_final)

final_auc <- fin_aug |>
  roc_auc('as.factor(gpa_split)',.fitted,
            event_level = "second")

red_auc <- augment(sig_fit) |>
  roc_auc('as.factor(gpa_split)',.fitted,
            event_level = "second")

final_auc_value <- final_auc$.estimate
red_auc_value <- red_auc$.estimate


cat("AUC for Reduced Model:", red_auc_value, "\n")
cat("AUC for Final Model:", final_auc_value, "\n")
```

We also checked AIC and BIC for the reduced and final models:

```{r}

cat("AIC for Reduced Model:", AIC(sig_fit), "\n")
cat("AIC for Final Model:", AIC(university_final), "\n")

cat("BIC for Reduced Model:", BIC(sig_fit), "\n")
cat("BIC for Final Model:", BIC(university_final), "\n")
```

Although the BIC for the final model is higher, because the aim of this study is to determine what combination of predictors works best to predict if a student has a high or low GPA, AIC is a more appropriate gauge for determining a better model. The AIC for the final model of 398.0 is lower than the AIC for the reduced model of 406.3. Therefore, we believe that our final model is a better model to predict a high or low GPA, and the addition of predictors `TotalSleepTime` and `daytime_sleep_lvl` are significant.

Finally, we assess the key assumptions of logistic regression within our model. All predictors show a linear relationship with the log-odds:

```{r}
final_pred <- predict(university_final, type = "link")

ggplot(data = fin_aug, aes(x = TotalSleepTime, y = final_pred)) + 
  geom_point() + 
  geom_smooth(method = "lm", color = "blue") + 
  labs(
    title = "Logit for TotalSleepTime", 
    y = "Log-odds(Fitted values)"
  )

ggplot(data = fin_aug, aes(x = university, y = final_pred)) + 
  geom_boxplot(fill = "lightblue", color = "black") +  # Boxplot for categorical variables
    labs(
    title = "Logit for University", 
    y = "Log-odds(Fitted values)"
  )

ggplot(data = fin_aug, aes(x = factor(demo_race), y = final_pred)) + 
  geom_boxplot(aes(fill = factor(demo_race)), color = "black") +
    labs(
    title = "Logit for demo_race", 
    y = "Log-odds(Fitted values)"
  )

ggplot(data = fin_aug, aes(x = threshold_gpa, y = final_pred)) + 
  geom_boxplot(fill = "blue", color = "black") +  # Boxplot for categorical variables
    labs(
    title = "Logit for threshold_gpa", 
    y = "Log-odds(Fitted values)"
  )

ggplot(data = fin_aug, aes(x = daytime_sleep_lvl, y = final_pred)) + 
  geom_boxplot(fill = "darkblue", color = "black") +  # Boxplot for categorical variables
    labs(
    title = "Logit for daytime_sleep_lvl", 
    y = "Log-odds(Fitted values)"
  )

```

There is also no multicollinearity between predictors included in this model as the VIFs are all far below the threshold of 10.

When checking for Cook's Distance, no data points were found to have a Cook's Distance greater than 1, indicating that there are no influential points.

```{r}
vif(university_final)
vif(sig_fit)

cooks_d <- cooks.distance(university_final)
cooks_d_df <- tibble(cooks_d = cooks_d)

inf_points <- cooks_d_df |>
  filter(cooks_d > 1)
inf_points

fin_aug |>
ggplot(aes(x = .fitted, y = .std.resid)) +
  geom_point(aes(color = .cooksd)) +
  scale_color_gradient(low = "blue", high = "orange") +
  labs(x = "Fitted Values", y = "Standardized Residuals", 
       title = "Standardized Residuals vs. Fitted Values by Sport Type and Cook's Distance",
       color = "Cook's Distance", shape = "Sport") +
  geom_hline(yintercept = 0, color = "black")
```

**INCLUDE GRAPH OR NO?** do we need fitted vs resid or ?

Although logistic regression assumes independence between observations, we grouped our observations by the type of university attended, which could introduce potential correlation between observations by school. However, we continued with logistic regression for the following reasons:

-   We wanted to predict a categorical response variable, high vs. low GPA, from various predictors, and find the best model (from this dataset) to do so.

-   We used `university` as one of the predictor variables to account for differences between observations and it was proven to be a significant predictor of `gpa_split` through our analysis.

**CONFIDENCE MATRIX\*\* not working**

-   after making need to calculate accuracy and misclassification rates

```{r}

fin_aug_2 <- augment(university_final)
confusion_matrix <- table(Predicted = fin_aug)
# fin_aug <- augment(university_final)
# red_aug <- augment(sig_fit)
# 
# final_aug$gpa_split <- final_aug$`as.factor(gpa_split)`
# red_aug$gpa_split <- red_aug$`as.factor(gpa_split)`
# 
# 
# final_pred <- predict(university_final, type = "response")
# red_pred <- predict(sig_fit, type = "response")
# 
# final_class <- if_else(final_pred > 0.5, "first", "second")
# red_class <- if_else(red_pred > 0.5, "first", "second")
# 
# final_aug |>
#   conf_mat(gpa_split, final_class)
# 
# red_aug |>
#   conf_mat(truth = all_of("as.factor(gpa_split)"), estimate = red_class)
```

------------------------------------------------------------------------

Things that still need to be done:

Results Section:

In this section, you will output the final model and include a brief discussion of the model assumptions, diagnostics, and any relevant model fit statistics.

This section also includes initial interpretations and conclusions drawn from the model.

**Introduction and data:**

Explain the univariate and bivariate EDA.

(why did we use term gpa, cum gpa and gpa_split as different response variables? how did we decide that gpa_split was the best response variable?)

Explain if there are any interaction terms/ if we should transform any variables.

Explain transformation of variables:

-   daytime sleep lvl

-   gpa_threshold

-   gpa_split

-   university (check this explanation)

**Methodology:**

Explain model selection ( Explain how we got to the sig_fit model from the log_model/ why did we choose log_reg

Explain how we got to the university_final model from the sig_fit model )

Included in that is:

-   anova tables
-   The hypothesis test / drop in deviance test results

**Results:**

Interpret AIC, ROC, AUC for final model, explain results/ compare to the sig_fit model.

-   can't do R-sq for log reg
