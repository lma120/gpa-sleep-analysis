---
title: "The Impact of Race, Gender, First-gen Status, Sleep Amount, and Institution Type on the Academic Performance of College Students"
author: "Wale: Liane, Amy, Eshan, Will"
date: "10/31/24"
format: pdf
execute: 
  warning: false
  message: false
  echo: false
editor: visual
bibliography: data/references.bib
---

```{r}
#| label: load packages and data
library(tidyverse)
# library(GGally)
# library(dplyr)
library(knitr)
library(broom)
#library(pROC)
library(car)
library(yardstick)
library(patchwork)
#library(rms)
library(gridExtra)

university_dataset <- read_csv("data/cmu-sleep.csv")
#glimpse(university_dataset)
```

## Introduction and Data

#### Project Motivation and Research Question

As college students, we are interested in exploring how academic performance is affected differently by lack of sleep, whether a student goes to a public or private university, and more as many of these issues affect us currently. As shown in previous research, sleep impacts students’ academic achievement significantly [@effect_sleep], but we aim to explore this in terms of the time students went to bed, average sleep time, and more while also accounting for students’ background and the type of university they go to. It is generally understood that lower levels of sleep negatively impact academic performance, but we are interested in how this impact varies or might be challenged by different factors and how we may be able to predict academic performance based on different factors. We hypothesize that the average time in bed will have the largest effect on cumulative GPA and that having less variation in bed time will lead to a higher cumulative GPA. We also anticipate the type of university students attend and first-gen status to have an affect on students' GPA. Our research question is as follows: What factors affect academic performance (in terms of GPA) of college students?

#### Dataset and Key Variables

The data was originally collected with participants being first-year students at the following three universities: Carnegie Mellon University (CMU), a STEM-focused private university, The University of Washington (UW), a large public university, and Notre Dame University (ND), a private Catholic university. To collect data on sleep, each participating student was given a device to track their sleep and physical activity for a month in the spring term of years 2016 to 2019, and demographic data was provided by university registrars [@cmu_sleep].

There were originally 634 observations, representing the 634 participants in this study. We filtered out students whose data was collected less than 50% of the term, leaving us with 588 participants. `demo_race`is a binary variable with 0 being underrepresented students and 1 being non-underrepresented students. Students are considered underrepresented if either parent is Black, Hispanic or Latino, Native American, or Pacific, and students are deemed non-underrepresented if both parents have White or Asian ancestry. The gender of the subject is also binary with 0 being male and 1 being female. First-generation status is binary with 0 being non-first gen and 1 being first-gen. The mean successive squared difference of bedtime measures the bedtime variability, specifically the average of the squared difference of bedtime on consecutive nights. To measure academic performance, we will be using variables `term_gpa` and `cum_gpa` (cumulative GPA) as response variables. The cumulative GPA is the GPA of each student's freshman fall semester.

```{r}
university_clean <- university_dataset |>
  mutate(university = case_when(
    study %in% c(1, 5) ~ "stem_priv",
    study %in% c(2, 3) ~ "public",
    study == 4 ~ "cath_priv"
  )) |>
  filter(frac_nights_with_data > .50) |>
  filter(demo_firstgen != 2)
#glimpse(university_clean)

```

Then, we created four new variables to help with our analysis. First, we created `gpa_split` which is a binary variable that classifies GPA as "High" or "Low". A "High" GPA was determined as above the 75th percentile (3.81 GPA) of the overall term GPAs. "Low" GPA represents all the term GPAs below the 75th percentile. We then created a new variable `university`, which combines studies done at the same universities on different years ranging from 2016 to 2019. We also created the variables `threshold_gpa`, and `daytime_sleep_lvl`. `threshold_gpa` is a binary variable which classifies GPA as "high" if a student's term GPA is higher than or equal to their cumulative GPA, and "low" if it is less than their cumulative GPA. `daytime_sleep_lvl` is a binary variable that uses a threshold of 60 minutes to determine whether a student's average daytime sleep is long (high) or short (low).

#### Univariate Exploratory Data Analysis

```{r}
# Generate summary statistics table
summary_table <- university_clean %>%
  summarize(
    Min = min(term_gpa),
    Q1 = quantile(term_gpa, 0.25),
    Median = median(term_gpa),
    Mean = mean(term_gpa),
    Q3 = quantile(term_gpa, 0.75),
    Max = max(term_gpa),
    SD = sd(term_gpa)
  ) |>
  kable(digits = 3, caption = "Summary Statistics of Term GPA")

# Print summary table
summary_table

gpa_ss <- university_clean |>
  group_by(university) |>
   summarize(
     mean_cgpa = mean(cum_gpa, na.rm = TRUE),
     median_cgpa = median(cum_gpa, na.rm = TRUE),
     sd_cgpa = sd(cum_gpa, na.rm = TRUE),
     min_cgpa = min(cum_gpa, na.rm = TRUE),
     max_cgpa = max(cum_gpa, na.rm = TRUE),
     count = n()
   ) |>
   kable(digits = 3, caption = "Summary of Cumulative GPA by University")
 gpa_ss

#mutating variables
university_clean <- university_clean |>
  mutate(gpa_split = if_else(
    term_gpa >= 3.81, "High GPA", "Low GPA"),
  threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"),
  daytime_sleep_lvl = if_else(daytime_sleep > 60, "high", "low"))


```

The summary table on the left shows the summary statistics for term GPA. The top 25% of students had term GPAs above 3.81, and the bottom 25% had term GPAs below 3.24. This suggests that the majority of students are doing well in school. 

The summary table on the right shows the summary statistics for cumulative GPA. One interesting piece of information is the minimum GPA from the catholic private school is significantly higher than the stem private school and the public school. The catholic private school’s mean and median cumulative GPA are also higher than the other two schools. This could suggest that the catholic private school has higher grade inflation than the other two schools.

```{r}
#| label: univariate-EDA

# university_clean |> 
#   select(term_gpa, cum_gpa, TotalSleepTime, bedtime_mssd, demo_firstgen, university, daytime_sleep) |>
#   ggpairs()

pg1 <- university_clean |>
  ggplot(aes(x = term_gpa)) +
  geom_histogram() +
  labs(title = "Distribution of the Term GPA",
       x = "Term GPA",
       y = "Count") + 
      theme(
        plot.title = element_text(size = 9),
        plot.subtitle = element_text(size = 7),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7)
)

pg2 <- university_clean |>
  ggplot(aes(x = term_gpa)) +
  geom_histogram(bins = 12) +
  labs(title = "Distribution of the Term GPA",
       subtitle = "by University",
       x = "Term GPA",
       y = "Count") +
  facet_wrap(~university) + 
      theme(
        plot.title = element_text(size = 9),
        plot.subtitle = element_text(size = 7),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7)
)

pg3 <- university_clean |>
  ggplot(aes(x = cum_gpa)) +
  geom_histogram() +
  labs(title = "Distribution of the Cumulative GPA",
       x = "Cumulative GPA",
       y = "Count") +
      theme(
  plot.title = element_text(size = 9),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7)
)

pg4 <- university_clean |>
  ggplot(aes(x = cum_gpa)) +
  geom_histogram(bins = 12) +
  labs(title = "Distribution of the Cumulative GPA",
       subtitle = "by University",
       x = "Cumulative GPA",
       y = "Count") +
  facet_wrap(~university) +
      theme(
  plot.title = element_text(size = 9),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
  plot.subtitle = element_text(size = 7)
)


gpa_plots <- (pg1 | pg2) / (pg3 | pg4) 
gpa_plots 


#a lot of NA values for the Catholic school -> will not use this variable
#for analyses


```

These four graphs show the counts of term GPA and cumulative GPA, split by university type, and all together. One notable point is that for the catholic private school and the public school, there is a very significant difference in the count of 4.0 term GPA and 4.0 cumulative GPA. This suggests that there were a number of students at these two schools who did not have a 4.0 GPA first semester, but had a 4.0 GPA second semester. This contrasts the stem private school, whose count of 4.0 GPA’s for both term GPA and cumulative GPA are very close. This suggests that at the stem private school, the student’s who had a 4.0 first semester are also getting a 4.0 in the second semester.

```{r}

pg5 <- university_clean |>
  ggplot(aes(x = TotalSleepTime)) + 
  geom_histogram() +
  labs(title = "Distribution of the Total Sleep Time",
       x = "Total Sleep Time in Minutes", #consider switching to hours
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)


# pg6 <- university_clean |>
#   ggplot(aes(x = bedtime_mssd)) + 
#   geom_histogram() +
#   labs(title = "Distribution of the Bedtime Variability",
#        x = "Mean successive squared difference of bedtime",
#        y = "Count") +
#     theme(
#   plot.title = element_text(size = 10)
# )


pg7 <- university_clean |>
  ggplot(aes(x = frac_nights_with_data)) + 
  geom_histogram() +
  labs(title = "Distribution of the Fraction of Nights With Data",
       x = "Fraction of Nights With Data",
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)


pg8 <- university_clean |>
  ggplot(aes(x = daytime_sleep)) + 
  geom_histogram() +
  labs(title = "Distribution of Daytime Sleep",
       x = "Daytime Sleep in Minutes",
       y = "Count") +
    theme(
  plot.title = element_text(size = 10)
)

#sleep_plots <- (pg5 | pg6) / (pg7 | pg8)
#sleep_plots
```

**Bivariate Exploratory Data Analysis**

```{r, fig.width = 12, fig.height = 5}



p5 <- university_clean |>
  ggplot(aes(
    x = university,
    y = term_gpa,
    fill = university
  )) +
  geom_boxplot() +
  labs(
    title = "Term GPA by University Type",
    x = "University",
    y = "Term GPA"
  ) +
    theme(
    plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    legend.position = "bottom",
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 9),
    legend.direction = "horizontal",
    legend.key.size = unit(7, "pt")
  )


p7 <- university_clean |>
  ggplot(aes(
    x = bedtime_mssd, 
    y = term_gpa, 
    color = university
  )) +
  geom_point(alpha = 0.6) + 
  geom_smooth(method = "lm", se = FALSE) + 
  labs(x = "Bedtime MSSD",
       y = " Term GPA/4.0",
       title = "Relationship between Bedtime MSSD \n and Term GPA" ) +
    theme(
    plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    legend.position = "bottom",
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 9),
    legend.direction = "horizontal",
    legend.key.size = unit(7, "pt")
  )

#keep
p12 <- ggplot(university_clean, aes(x = university, fill = gpa_split)) +
  geom_bar(position = "dodge") +
  labs(
    title = "Distribution of High and Low \n Term GPA by University Type",
    x = "University Type",
    y = "Count",
    fill = "GPA"
  ) +
    theme(
    plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
    axis.title.x = element_text(size = 9),
    axis.title.y = element_text(size = 9),
    legend.text = element_text(size = 9),
    legend.title = element_text(size = 9),
    legend.direction = "horizontal",
    legend.position = "bottom",
    legend.key.size = unit(7, "pt")
  )

grid.arrange(p7, p12, ncol =2)
```

```{r}
fig.width = 5
fig.height = 4

p4 <- university_clean |>
  mutate(threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"))|>
  ggplot(aes(x = TotalSleepTime/60, y = term_gpa, color = factor(threshold_gpa))) +
  facet_wrap(~ university,
             labeller = labeller(
              university = c("cath_priv" = "Private (Catholic)",
                             "public" = "Public",
                             "stem_priv" = "Private (STEM)"))) + 
  geom_point(alpha = 0.3) +
  geom_smooth(aes(color = factor(threshold_gpa)), method = "lm", se = FALSE) +
  scale_color_manual(values = c("low" = "blue", "high" = "red")) +
  labs(
    title = "Term GPA vs Total Sleep Time",
    subtitle = "By University Type",
    x = "Total Sleep Time (hours)",
    y = "Term GPA /4.0",
    color = "GPA Threshold"
 ) +
    theme(
    plot.title = element_text(size = 8, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 8, face = "bold", hjust = 0.5),
    legend.position = "top",
    axis.title.x = element_text(size = 7),
    axis.title.y = element_text(size = 7),
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 7)
  )

p8 <- university_clean |>
  ggplot(aes(
    x = daytime_sleep,
    y = term_gpa
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Term GPA vs. Daytime Sleep",
    x = "Daytime Sleep (minutes)",
    y = "Term GPA /4.0"
  ) + theme(
    axis.title.x = element_text(size = 7),
    axis.title.y = element_text(size = 7),
    plot.title = element_text(size = 9, hjust = 0.5, face = "bold"),
    legend.text = element_text(size =7),
    legend.title = element_text(size = 7),
    legend.direction = "horizontal",
    legend.postion = "bottom"
  )

# p9 <- university_clean |>
#   mutate(threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"))|>
#   ggplot(aes(
#     x = Zterm_units_ZofZ,
#     y = TotalSleepTime,
#     color = university
#   )) + 
#   facet_wrap(~threshold_gpa) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#    labs(x = "Term Units Z score",
#         y = " Total Sleep Time",
#         title = "Total Sleep Time by Term Units Z-score")

p10 <- university_clean |>
  mutate(threshold_gpa = if_else(term_gpa < cum_gpa, "low", "high"))|>
  mutate(daytime_sleep_lvl = if_else(daytime_sleep > 60, "high", "low")) |>
  ggplot(aes(
    x = daytime_sleep,
    y = term_gpa,
    color = daytime_sleep_lvl 
  )) +
  facet_wrap(~threshold_gpa) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Term GPA by Daytime Sleep",
    x = "Daytime Sleep (minutes)",
    y = "Term GPA /4.0",
    color = "Daytime Sleep Length"
  ) +
  theme(legend.position = "top",
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
        plot.title = element_text(size = 9, hjust = 0.5, face = "bold"),
        legend.text = element_text(size = 7),
        legend.title = element_text(size = 7))


grid.arrange(p4,p10, ncol = 2)
```

First, we looked at the relationship between total sleep time and cumulative GPA across the factors of race, gender and first-generation status. The slopes of the line of best fit for each level of each factor were all parallel, indicating that there is most likely no interaction effect between these factors with total sleep time (refer to appendix figure 1).

From the graphs above, a few of the key variables seem to have some interaction effects, and a few others do not. The first graph is a scatterplot of the relationship between total sleep time and cumulative GPA, factored by race, where red points were underrepresented students, and blue points were non-underrepresented students. The slopes of the lines best fit for each level are very similar but the slope for the underrepresented students is slightly larger than the slopes for non-underrepresented students, so there might be an interaction effect there that is worth further analysis.

The second graph, is also a scatterplot of the relationship between total sleep time and cumulative GPA, but instead factored by gender, where the red points represent male gender and the blue points represent female gender. The slopes for the line best fit for each level were essentially the same, so there is no obvious interaction effect in this graph that is worth further analysis.

The third graph shows the relationship between a student's term GPA and their total sleep time, but is facet wrapped by the university the student attended. A fourth variable, `threshold_gpa`, is a factor of 0 and 1, where 0 represents that the student's term GPA is greater than or equal to their cumulative GPA, and 1 represents that the student's term GPA is less than their cumulative GPA. This essentially tells us whether the student's term GPA is better or worse than their average GPA. Since this study only collected data during the singular term, this variable will help us determine whether a student with a low term GPA relative to their cumulative GPA is predictive of that student's total sleep time. There are a few interesting things to note of this graph. First, the term GPA of students at the STEM university seem to be more variable than the other two universities, and the total sleep time of the students at the STEM university seem to be on average lower than the other two universities.

In regards to the interaction effects, it seems as if for all three universities there is an interaction effect between students whose term GPA is less than their cumulative and student's whose term GPA is greater than or equal to their cumulative GPA. We assume this, because for all three universities, we fit a line best fit to for both term GPA \< cumulative GPA and vise versa, and the slopes of both lines for all three universities are different. Most notably, for the private catholic university and the public university, the slopes of the level for term GPA \< cumulative GPA is greater than the slopes of the level for term GPA $\ge$ cumulative GPA. This means that there is a potential interaction effect that could be explored further.

Another graph with another potential interaction effect is the sixth graph, which plots the relationship between the mean successive squared difference of bedtimes (bedtime_mssd) and a student's cumulative GPA. The points on this scatterplot were differentiated by university, with red representing the catholic private university, green representing the public university, and blue representing the STEM private university. We fit the line best fit for each of these levels, and the slope of the line for the catholic private university and the stem private university were essentially the same, but the slope of the line for the public university was slightly smaller, which means there could be a potential interaction effect there that is worth further exploration.

## Methodology

Our general thought process to try and model out an answer to our research question was to think about GPA as our response variable as stated above. We felt logistic regression was a better choice using our transformed binary gpa variable, gpa_split, where a GPA above 3.0 was considered "High", and below was considered "Low." We were more concerned with understanding and predicting general ranges of academic performance as opposed to a certain GPA mark. To begin, we fit a logistic regression model with all of the variables we spoke of above (demographic variables, sleep-related variables, and a performance variable (threshold GPA)).

```{r}
university_clean$university <- factor(university_clean$university)
university_clean$university <- relevel(university_clean$university , ref = "public")

log_model <- glm(as.factor(gpa_split) ~ TotalSleepTime + university + daytime_sleep_lvl + demo_firstgen + demo_gender + bedtime_mssd + demo_race + threshold_gpa, data = university_clean, family = binomial)

tidy(log_model) |>
  kable(digits = 3)
```

We saw that (by p-value), some of these predictors were not considered significant, and so we needed to do some more analysis to figure out what was necessary to use in the final model.

**Analysis of Deviance Table**

Model 1: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa`

Model 2: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime`

```{r}

sig_fit <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa, data = university_clean, family = binomial) 
tidy(sig_fit) |>
  kable(digits = 3)

university_fit1 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime, data = university_clean, family = binomial)

anova(sig_fit, university_fit1, test = "Chisq") |>
  kable(digits = 3)
# TotalSleepTime we should include.

```

We then created a new model, sig_fit, that isolated only the variables that were significant in the output from our original model. However, there were certain variables that we felt were still necessary to assess further, and so we used a Drop-in Deviance test to compare two models, the exact same, except one included TotalSleepTime, and the other didn't. Given TotalSleepTime being central to our entire research motivation, we wanted to investigate further, and our anova table showed us the p-value being 0.02, meaning its inclusion significantly improves the fit of the model.

**Analysis of Deviance Table**

Model 1: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime`

Model 2: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + bedtime_mssd`

```{r}
university_fit2 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + bedtime_mssd, data = university_clean, family = binomial)

ufit2_anova <- anova(university_fit1, university_fit2, test = "Chisq")

simp_ufit2_anova <- ufit2_anova[, c("Df","Deviance","Pr(>Chi)")]

ufit2_anova |>
  kable(digits = 3)

```

With a p-value of 0.06, greater than the threshold of 0.05, we can conclude that the inclusion of bedtime_mssd does not significantly improve the model fit and don't include it in our final model.

**Analysis of Deviance Table**

Model 1: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime`

Model 2: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen`

```{r}
university_fit3 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen, data = university_clean, family = binomial) #final!

ufit3_anova <- anova(university_fit1, university_fit3, test = "Chisq")

simp_ufit3_anova <- ufit3_anova[, c("Df","Deviance","Pr(>Chi)")]

ufit3_anova |>
  kable(digits = 3)
```

With a p-value of 0.00409, we can conclude that the inclusion of demo_firstgen significantly improves the model fit and should be included in our final model.

**Analysis of Deviance Table**

Model 1: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen`

Model 2: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen + daytime_sleep_lvl`

```{r}
university_fit4 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + daytime_sleep_lvl + TotalSleepTime + demo_firstgen, data = university_clean, family = binomial)

ufit4_anova <- anova(university_fit3, university_fit4, test = "Chisq")
simp_ufit4_anova <- ufit4_anova[, c("Df","Deviance","Pr(>Chi)")]

ufit4_anova |>
  kable(digits = 3)

```

With a p-value of 0.4, which is greater than the threshold, we fail to reject the null hypothesis and can conclude that the inclusion of daytime_sleep_lvl does not significantly improve the model and do not include it in our final model.

We then decided to check certain interaction effects between significant main effects due to graphs in EDA (or figures in appendix?) \*\* FIX THIS

**Interaction Effect Analyses:**

**Analysis of Deviance Table**

Model 1: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen`

Model 2: `as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen + university*TotalSleepTime`

```{r}
int_fit <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + demo_firstgen + TotalSleepTime + university*TotalSleepTime, data = university_clean, family = binomial)

int1_anova <- anova(university_fit3, int_fit, test = "Chisq")

sim_int1_anova <- int1_anova[, c("Df","Deviance","Pr(>Chi)")]

int1_anova |>
  kable(digits = 3)
```

With a p-value of 0.8 which is greater than the threshold of 0.05, we can conclude that the interaction effects between university and TotalSleepTime are not significant enough to be included in the final model.

```{r}
int_fit2 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + demo_firstgen + TotalSleepTime + university*threshold_gpa, data = university_clean, family = binomial)

int2_anova <- anova(university_fit3, int_fit2, test = "Chisq")

sim_int2_anova <- int2_anova[, c("Df","Deviance","Pr(>Chi)")]

int2_anova |>
  kable(digits = 3)

```

With a p-value of 0.5, greater than the threshold of 0.05, we can conclude that the interaction effects between university and threshold GPA are not significant enough to be included in the final model.

```{r}
int_fit3 <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + demo_firstgen + TotalSleepTime + TotalSleepTime*threshold_gpa, data = university_clean, family = binomial)

int3_anova <- anova(university_fit3, int_fit3, test = "Chisq")

sim_int3_anova <- int3_anova[, c("Df","Deviance","Pr(>Chi)")]

int3_anova |>
  kable(digits = 3)
```

We then decided to check for multicollinearity given the interconnected nature of some of the variables. We had to use GVIF because there are a few categorical predictors used.

```{r}
university_final <- glm(as.factor(gpa_split) ~ university + demo_race + threshold_gpa + TotalSleepTime + demo_firstgen, data = university_clean, family = binomial) #final model! university_fit3

vif(university_final) |>
  kable(digits = 3)
```

For our final model, the GVIFs (adjusted) for all variables are not greater than 10 and are very close to 1, so we can confidently assume no multicollinearity.

## Results

The final model we determined is:

EDIT THESE WITH FINAL MODELS AFTER MODEL IS FINALIZED!!

$$
logit(p_{high\_gpa}) = 4.206 - 0.871 \times universitycath\_priv \\ -0.286 \times universitystem\_priv \\
- 0.694 \times demo\_race
$$

$$
- \\0.475 \times threshold\_gpalow
\\ - 0.005 \times TotalSleepTime \\- 1.088 \times demo\_firstgen
$$

$$
p_{high\_gpa} = \frac {1} {1+e^{x}} 
$$

Where $x$ represents the logit equation shown above.

```{r}
tidy(university_final) |>
  kable(digits = 3)
```

To confirm that the final model with predictors `university`, `demo_race`, `threshold_gpa`, `TotalSleepTime`, and `daytime_sleep_lvl` is better for predicting a high or low GPA (`gpa_split`) than the reduced model with initial significant predictors `university`, `demo_race`, and `threshold_gpa`, ROC and AUC were calculated for both models and compared.

The final model we chose showed a larger AUC. The area under the curve for the final model is 0.778, whereas for the reduced model it is 0.75, showing that this final model maximizes sensitivity, the True Positive Rate, and minimizes 1 - specificity, the False Positive Rate, slightly better than the reduced model.

```{r}

final_roc <- augment(university_final) |>
  roc_curve('as.factor(gpa_split)', .fitted, event_level = "second")

red_roc <- augment(sig_fit) |>
  roc_curve('as.factor(gpa_split)', .fitted, event_level = "second")

combined_plot <- autoplot(red_roc, color = "blue") +
  ggtitle("ROC Curves") +
  xlab("1 - Specificity") +
  ylab("Sensitivity") +
  geom_line(data = final_roc, aes(x = 1 - specificity, y = sensitivity, color = "Final Model")) + 
  geom_line(data = red_roc, aes(x = 1 - specificity, y = sensitivity, color = "Reduced Model")) +
  scale_color_manual(values = c("Final Model" = "red", "Reduced Model" = "black")) +
  labs(color = "Model") +
  theme(plot.title = element_text(size = 9, face = "bold"),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7),
        legend.text = element_text(size = 7),
        legend.title = element_text(size = 7),
        legend.position = "bottom")

fin_aug <- augment(university_final)

final_auc <- fin_aug |>
  roc_auc('as.factor(gpa_split)',.fitted,
            event_level = "second")

red_auc <- augment(sig_fit) |>
  roc_auc('as.factor(gpa_split)',.fitted,
            event_level = "second")

final_auc_value <- final_auc$.estimate
red_auc_value <- red_auc$.estimate


cat("AUC for Reduced Model:", red_auc_value, "\n")
cat("AUC for Final Model:", final_auc_value, "\n")

cooks_d <- cooks.distance(university_final)
cooks_d_df <- tibble(obs = 1:length(cooks_d), cooks_d = cooks_d)


inf_points <- cooks_d_df |>
  filter(cooks_d > 1)
inf_points


cook_plot <- cooks_d_df |>
  ggplot(aes(
    x = obs,
    y = cooks_d
  )) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Cook's Distance",
    x = "Observation Number",
    y = "Cook's Distance"
  ) +
  theme(plot.title = element_text(size = 9, face = "bold"),
        axis.title.x = element_text(size = 7),
        axis.title.y = element_text(size = 7))
  
grid.arrange(combined_plot, cook_plot, ncol = 2)

```

When checking for Cook's Distance, no data points were found to have a Cook's Distance greater than 1 with most far below 1, indicating that there are no influential points.

We also checked AIC and BIC for the reduced and final models:

```{r}

cat("AIC for Reduced Model:", AIC(sig_fit), "\n")
cat("AIC for Final Model:", AIC(university_final), "\n")

cat("BIC for Reduced Model:", BIC(sig_fit), "\n")
cat("BIC for Final Model:", BIC(university_final), "\n")
```

Both the AIC and the BIC for the final model are lower than those for the reduced model as shown above. Therefore, we believe that our final model is a better model to predict a high or low GPA, and the addition of predictors `TotalSleepTime` and `daytime_sleep_lvl` are significant.

Finally, we assess the key assumptions of logistic regression within our model. All predictors show a linear relationship with the log-odds:

```{r, fig.width=15, fig.height=8}
final_pred <- predict(university_final, type = "link")

pa1 <- ggplot(data = fin_aug, aes(x = TotalSleepTime, y = final_pred)) + 
  geom_point() + 
  geom_smooth(method = "lm", color = "blue") + 
  labs(
    title = "Logit for TotalSleepTime", 
    y = "Log-odds(Fitted values)"
  ) + 
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 20),
    axis.title = element_text(size = 15),       
    axis.text = element_text(size = 15)
  )


pa2 <- ggplot(data = fin_aug, aes(x = university, y = final_pred)) + 
  geom_boxplot(fill = "lightblue", color = "black") +
    labs(
    title = "Logit for University", 
    y = "Log-odds(Fitted values)"
  ) + 
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 20),
    axis.title = element_text(size = 15),       
    axis.text = element_text(size = 15)
  )


pa3 <- ggplot(data = fin_aug, aes(x = factor(demo_race), y = final_pred)) + 
  geom_boxplot(aes(fill = factor(demo_race)), color = "black") +
    labs(
    title = "Logit for demo_race", 
    y = "Log-odds(Fitted values)"
  ) + 
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 20),
    axis.title = element_text(size = 15),       
    axis.text = element_text(size = 15),
    legend.text = element_text(size = 15),    
    legend.title = element_text(size = 15)
  )


pa4 <- ggplot(data = fin_aug, aes(x = threshold_gpa, y = final_pred)) + 
  geom_boxplot(fill = "blue", color = "black") +
    labs(
    title = "Logit for threshold_gpa", 
    y = "Log-odds(Fitted values)"
  ) + 
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 20),
    axis.title = element_text(size = 15),       
    axis.text = element_text(size = 15)
  )


pa5 <- ggplot(data = fin_aug, aes(x = factor(demo_firstgen), y = final_pred)) + 
  geom_boxplot(fill = "darkblue", color = "black") +
    labs(
    title = "Logit for demo_firstgen", 
    y = "Log-odds(Fitted values)"
  ) + 
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 20),
    axis.title = element_text(size = 15),       
    axis.text = element_text(size = 15)
  )

grid.arrange(pa1, pa2, pa3, pa4, pa5, ncol = 3)


```

There is also no multicollinearity between predictors included in this model as the VIFs are all far below the threshold of 10.

```{r}
vif(university_final) |>
  kable(digits = 3)
```

Although logistic regression assumes independence between observations, we grouped our observations by the type of university attended, which could introduce potential correlation between observations by school. However, we continued with logistic regression for the following reasons:

-   We wanted to predict a categorical response variable, high vs. low GPA, from various predictors, and find the best model (from this dataset) to do so.

-   We used `university` as one of the predictor variables to account for differences between observations and it was proven to be a significant predictor of `gpa_split` through our analysis.

## Discussion and Conclusion

insert conclusion here

## Appendix

#### Figure 1.

```{r}

fig.width = 5
fig.height = 4

p1 <- university_clean |>
  ggplot(aes(
    x = TotalSleepTime/60,
    y = cum_gpa,
    color = factor(demo_race, labels = c("Underrepresented", "Non-Underrepresented"))
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "By Race",
    x = "Total Sleep Time (hours)",
    y = "Cumulative GPA /4.0",
    color = "Underrepresented Status"
  ) +
  theme(
    plot.title = element_text(size = 7, hjust = 0.5, face = "bold"),
    legend.position = "bottom",
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 7),
    aspect.ratio = 1.5,
    axis.title.x = element_text(size = 7),
    axis.title.y = element_text(size = 7),
    legend.direction = "vertical"
  )


p2 <- university_clean |>
  filter(!is.na(demo_gender)) |>
  ggplot(aes(
    x = TotalSleepTime,
    y = cum_gpa,
    color = factor(demo_race, labels = c("Male", "Female"))
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "By Gender",
    x = "Total Sleep Time (hours)",
    y = "Cumulative GPA /4.0",
    color = "Gender"
  ) +
  theme(
    plot.title = element_text(size = 7, hjust = 0.5, face = "bold"),
    legend.text = element_text(size = 7),
    legend.position = "bottom",
    legend.title = element_text(size = 7),
    aspect.ratio = 1.5,
    legend.direction = "vertical",
    axis.title.x = element_text(size = 7),
    axis.title.y = element_text(size = 7),
  )


p3 <- university_clean |>
  filter(!is.na(demo_firstgen)) |>
  ggplot(aes(
    x = TotalSleepTime,
    y = cum_gpa,
    color = factor(demo_firstgen, labels = c("Not First-Generation", "First-Generation"))
  )) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "By First-Generation Status",
    x = "Total Sleep Time (hours)",
    y = "Cumulative GPA /4.0",
    color = "First-Generation Status"
  ) +
  theme(
    plot.title = element_text(size = 7, hjust = 0.5, face = "bold"),
    legend.position = "bottom",
    aspect.ratio = 1.5,
    legend.text = element_text(size = 7),
    legend.title = element_text(size = 7),
    legend.direction = "vertical",
    axis.title.x = element_text(size = 7),
    axis.title.y = element_text(size = 7),
  )

grid.arrange(p1, p2, p3, ncol = 3, top = "Cumulative GPA vs. Total Sleep Time")
```

#### Figure 2.

```{r}
na_table <- university_clean |>
  group_by(university) |>
  summarize(
    total_count = n(),
    na_count = sum(is.na(term_units)),
    non_na_count = sum(!is.na(term_units))
  ) |>
  kable(digits = 3, caption = "Counts of NA values by University")
na_table
```
